{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muller-Lyer Replication and Color Study Final Report - Analysis and Figures\n",
    "\n",
    "This notebook contains the final data analysis to accompany our report. For complete information on data collection and data cleaning steps see this repository: https://github.com/m6urns/muller-lyer-replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class = pd.read_csv('data/data_class.csv')\n",
    "data_intensive = pd.read_csv('data/data_intensive.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class (Intermittent Sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_group_performance(df):\n",
    "    # Convert is_correct to numeric (1 for True, 0 for False)\n",
    "    df['is_correct_numeric'] = df['is_correct'].astype(int)\n",
    "    \n",
    "    # Create group identifier\n",
    "    df['main_group'] = df['speed_group'].str.split(' - ').str[0]\n",
    "    df['speed_condition'] = df['speed_group'].str.split(' - ').str[1]\n",
    "    \n",
    "    # Print data validation\n",
    "    print(\"Data distribution across groups:\")\n",
    "    print(df.groupby(['main_group', 'speed_condition']).size())\n",
    "    \n",
    "    # Get first and last days overall\n",
    "    first_day = df['day'].min()\n",
    "    last_day = df['day'].max()\n",
    "    \n",
    "    # Filter for first and last days\n",
    "    first_last_data = df[df['day'].isin([first_day, last_day])].copy()\n",
    "    first_last_data['day_type'] = first_last_data['day'].map({first_day: 'First', last_day: 'Last'})\n",
    "    \n",
    "    # Calculate metrics for each group and condition\n",
    "    metrics = []\n",
    "    for group in ['Group 1', 'Group 2']:\n",
    "        for speed in ['Fast', 'Slow']:\n",
    "            for day_type in ['First', 'Last']:\n",
    "                mask = ((first_last_data['main_group'] == group) & \n",
    "                       (first_last_data['speed_condition'] == speed) & \n",
    "                       (first_last_data['day_type'] == day_type))\n",
    "                \n",
    "                group_data = first_last_data[mask]\n",
    "                \n",
    "                if len(group_data) > 0:\n",
    "                    metrics.append({\n",
    "                        'main_group': group,\n",
    "                        'speed_condition': speed,\n",
    "                        'day_type': day_type,\n",
    "                        'accuracy': group_data['is_correct_numeric'].mean(),\n",
    "                        'response_time': group_data['response_time'].mean(),\n",
    "                        'n_trials': len(group_data),\n",
    "                        'std_accuracy': group_data['is_correct_numeric'].std(),\n",
    "                        'std_rt': group_data['response_time'].std()\n",
    "                    })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    # Statistical tests\n",
    "    stats_results = {}\n",
    "    for group in ['Group 1', 'Group 2']:\n",
    "        group_data = first_last_data[first_last_data['main_group'] == group]\n",
    "        \n",
    "        # Accuracy\n",
    "        first_acc = group_data[group_data['day_type'] == 'First']['is_correct_numeric']\n",
    "        last_acc = group_data[group_data['day_type'] == 'Last']['is_correct_numeric']\n",
    "        if len(first_acc) > 0 and len(last_acc) > 0:\n",
    "            acc_ttest = stats.ttest_ind(first_acc, last_acc)\n",
    "            stats_results[f'{group}_accuracy'] = acc_ttest\n",
    "        \n",
    "        # Response Time\n",
    "        first_rt = group_data[group_data['day_type'] == 'First']['response_time']\n",
    "        last_rt = group_data[group_data['day_type'] == 'Last']['response_time']\n",
    "        if len(first_rt) > 0 and len(last_rt) > 0:\n",
    "            rt_ttest = stats.ttest_ind(first_rt, last_rt)\n",
    "            stats_results[f'{group}_rt'] = rt_ttest\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics_df,\n",
    "        'stats': stats_results,\n",
    "        # 'plot': fig\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_group_performance(data_class)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nMetrics Summary:\")\n",
    "print(results['metrics'])\n",
    "\n",
    "print(\"\\nStatistical Tests:\")\n",
    "for test_name, test_result in results['stats'].items():\n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"t-statistic: {test_result.statistic:.3f}\")\n",
    "    print(f\"p-value: {test_result.pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_arrow_length(df, line_plot_title=\"Accuracy by Length Difference\", \n",
    "                        bar_plot_title=\"Accuracy by Length Difference Category\"):\n",
    "    # Convert boolean to numeric\n",
    "    df['is_correct_numeric'] = df['is_correct'].astype(int)\n",
    "    \n",
    "    # Analysis of arrow length effect\n",
    "    df['length_diff_abs'] = abs(df['actual_difference'])\n",
    "    \n",
    "    # Group trials by difference magnitude\n",
    "    df['diff_category'] = pd.cut(df['length_diff_abs'], \n",
    "                                bins=[0, 5, 15, 25, 35, float('inf')],\n",
    "                                labels=['0-5', '6-15', '16-25', '26-35', '35+'])\n",
    "    \n",
    "    length_accuracy = df.groupby('diff_category')['is_correct_numeric'].agg([\n",
    "        'mean', 'std', 'count'\n",
    "    ]).round(3)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # 1. Line plot for accuracy by length difference\n",
    "    sns.lineplot(data=df, x='length_diff_abs', y='is_correct_numeric', \n",
    "                 ci=95, ax=ax1)\n",
    "    ax1.set_title(line_plot_title)\n",
    "    ax1.set_xlabel('Absolute Length Difference')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    \n",
    "    # 2. Bar plot for categorized length differences\n",
    "    sns.barplot(x=length_accuracy.index, y='mean',\n",
    "                data=length_accuracy, ax=ax2)\n",
    "    ax2.set_title(bar_plot_title)\n",
    "    ax2.set_xlabel('Length Difference (pixels)')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Calculate correlation between length difference and accuracy\n",
    "    length_corr = stats.pointbiserialr(df['length_diff_abs'], df['is_correct_numeric'])\n",
    "    \n",
    "    return {\n",
    "        'length_stats': length_accuracy,\n",
    "        'length_correlation': length_corr,\n",
    "        'plot': fig\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = analyze_arrow_length(data_class)\n",
    "\n",
    "results = analyze_arrow_length(\n",
    "    data_class,\n",
    "    line_plot_title=\"Accuracy by Length Difference - Intermittent\",\n",
    "    bar_plot_title=\"Accuracy by Length Difference Category - Intermittent\"\n",
    ")\n",
    "\n",
    "print(\"\\nLength Effect Statistics:\")\n",
    "print(results['length_stats'])\n",
    "print(\"\\nLength-Accuracy Correlation:\")\n",
    "print(f\"Correlation: {results['length_correlation'].correlation:.3f}\")\n",
    "print(f\"p-value: {results['length_correlation'].pvalue:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_arrow_color(df):\n",
    "    # Convert boolean to numeric\n",
    "    df['is_correct_numeric'] = df['is_correct'].astype(int)\n",
    "    \n",
    "    # Analysis of arrow color effects\n",
    "    color_accuracy = df.groupby('arrow_color')['is_correct_numeric'].agg([\n",
    "        'mean', 'std', 'count'\n",
    "    ]).round(3)\n",
    "    \n",
    "    # Calculate confidence intervals for colors\n",
    "    color_accuracy['ci'] = 1.96 * np.sqrt(\n",
    "        (color_accuracy['mean'] * (1 - color_accuracy['mean'])) / color_accuracy['count']\n",
    "    )\n",
    "    \n",
    "    # T-test for color effect\n",
    "    red_trials = df[df['arrow_color'] == 'red']['is_correct_numeric']\n",
    "    black_trials = df[df['arrow_color'] == 'black']['is_correct_numeric']\n",
    "    color_ttest = stats.ttest_ind(red_trials, black_trials)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # 1. Bar plot for color accuracy\n",
    "    sns.barplot(data=df, x='arrow_color', y='is_correct_numeric', \n",
    "                ci=95, ax=ax1)\n",
    "    ax1.set_title('Accuracy by Arrow Color')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    \n",
    "    # 2. Boxplot for response times by color\n",
    "    sns.boxplot(x='arrow_color', y='response_time', data=df, ax=ax2)\n",
    "    ax2.set_title('Response Times by Arrow Color')\n",
    "    ax2.set_ylabel('Response Time (seconds)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return {\n",
    "        'color_stats': color_accuracy,\n",
    "        'color_ttest': color_ttest,\n",
    "        'plot': fig\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_arrow_color(data_class)\n",
    "\n",
    "print(\"\\nColor Effect Statistics:\")\n",
    "print(results['color_stats'])\n",
    "print(\"\\nColor T-test:\")\n",
    "print(f\"t-statistic: {results['color_ttest'].statistic:.3f}\")\n",
    "print(f\"p-value: {results['color_ttest'].pvalue:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_control_comparison(df):\n",
    "    # Ensure boolean type for is_correct\n",
    "    df['is_correct'] = df['is_correct'].astype(bool)\n",
    "    \n",
    "    # Calculate percentages for control group\n",
    "    correct_percentage_control = (\n",
    "        df[df['is_control'] == True]\n",
    "        .groupby('day')['is_correct']\n",
    "        .mean() * 100\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate percentages for non-control group\n",
    "    correct_percentage_non_control = (\n",
    "        df[df['is_control'] == False]\n",
    "        .groupby('day')['is_correct']\n",
    "        .mean() * 100\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    correct_percentage_control.columns = ['Day', 'Correct Percentage (Control)']\n",
    "    correct_percentage_non_control.columns = ['Day', 'Correct Percentage (Non-Control)']\n",
    "    \n",
    "    # Extract values for statistics\n",
    "    control_percentages = correct_percentage_control['Correct Percentage (Control)'].tolist()\n",
    "    non_control_percentages = correct_percentage_non_control['Correct Percentage (Non-Control)'].tolist()\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    summary_stats = {\n",
    "        'control_mean': statistics.mean(control_percentages),\n",
    "        'non_control_mean': statistics.mean(non_control_percentages),\n",
    "        'days': correct_percentage_control['Day'].tolist(),\n",
    "        'control_percentages': control_percentages,\n",
    "        'non_control_percentages': non_control_percentages\n",
    "    }\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plot control group\n",
    "    ax.plot(correct_percentage_control['Day'], \n",
    "            correct_percentage_control['Correct Percentage (Control)'],\n",
    "            marker='o', linestyle='-', color='b', label='Control')\n",
    "    \n",
    "    # Plot non-control group\n",
    "    ax.plot(correct_percentage_non_control['Day'], \n",
    "            correct_percentage_non_control['Correct Percentage (Non-Control)'],\n",
    "            marker='o', linestyle='--', color='r', label='Non-Control')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_title('Correct Answer Percentage Over Days', fontsize=16)\n",
    "    ax.set_xlabel('Day', fontsize=14)\n",
    "    ax.set_ylabel('Correct Percentage (%)', fontsize=14)\n",
    "    ax.set_xticks(correct_percentage_control['Day'])\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return {\n",
    "        'summary_stats': summary_stats,\n",
    "        'plot': fig\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze control vs non-control group performance\n",
    "results = analyze_control_comparison(data_class)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nControl vs Non-Control Analysis:\")\n",
    "print(f\"Control group mean accuracy: {results['summary_stats']['control_mean']:.2f}%\")\n",
    "print(f\"Non-control group mean accuracy: {results['summary_stats']['non_control_mean']:.2f}%\")\n",
    "print(\"\\nDaily percentages:\")\n",
    "for day, control, non_control in zip(\n",
    "    results['summary_stats']['days'],\n",
    "    results['summary_stats']['control_percentages'],\n",
    "    results['summary_stats']['non_control_percentages']\n",
    "):\n",
    "    print(f\"Day {day}: Control = {control:.2f}%, Non-Control = {non_control:.2f}%\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External (Intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_group_performance(data_intensive)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nMetrics Summary:\")\n",
    "print(results['metrics'])\n",
    "\n",
    "print(\"\\nStatistical Tests:\")\n",
    "for test_name, test_result in results['stats'].items():\n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"t-statistic: {test_result.statistic:.3f}\")\n",
    "    print(f\"p-value: {test_result.pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = analyze_arrow_length(data_intensive)\n",
    "results = analyze_arrow_length(\n",
    "    data_intensive,\n",
    "    line_plot_title=\"Accuracy by Length Difference - Intensive\",\n",
    "    bar_plot_title=\"Accuracy by Length Difference Category - Intensive\"\n",
    ")\n",
    "\n",
    "print(\"\\nLength Effect Statistics:\")\n",
    "print(results['length_stats'])\n",
    "print(\"\\nLength-Accuracy Correlation:\")\n",
    "print(f\"Correlation: {results['length_correlation'].correlation:.3f}\")\n",
    "print(f\"p-value: {results['length_correlation'].pvalue:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_arrow_color(data_intensive)\n",
    "\n",
    "print(\"\\nColor Effect Statistics:\")\n",
    "print(results['color_stats'])\n",
    "print(\"\\nColor T-test:\")\n",
    "print(f\"t-statistic: {results['color_ttest'].statistic:.3f}\")\n",
    "print(f\"p-value: {results['color_ttest'].pvalue:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze control vs non-control group performance\n",
    "results = analyze_control_comparison(data_intensive)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nControl vs Non-Control Analysis:\")\n",
    "print(f\"Control group mean accuracy: {results['summary_stats']['control_mean']:.2f}%\")\n",
    "print(f\"Non-control group mean accuracy: {results['summary_stats']['non_control_mean']:.2f}%\")\n",
    "print(\"\\nDaily percentages:\")\n",
    "for day, control, non_control in zip(\n",
    "    results['summary_stats']['days'],\n",
    "    results['summary_stats']['control_percentages'],\n",
    "    results['summary_stats']['non_control_percentages']\n",
    "):\n",
    "    print(f\"Day {day}: Control = {control:.2f}%, Non-Control = {non_control:.2f}%\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'Group': ['Intermittent', 'Intermittent', 'Intermittent', 'Intermittent', 'Intermittent', 'Intermittent', 'Intermittent', 'Intermittent', \n",
    "              'Intensive', 'Intensive', 'Intensive', 'Intensive', 'Intensive', 'Intensive', 'Intensive', 'Intensive'],\n",
    "    'Condition': ['Experimental', 'Experimental', 'Experimental', 'Experimental', 'Control', 'Control', 'Control', 'Control',\n",
    "                 'Experimental', 'Experimental', 'Experimental', 'Experimental', 'Control', 'Control', 'Control', 'Control'],\n",
    "    'Quiz Speed': ['Fast', 'Fast', 'Slow', 'Slow', 'Fast', 'Fast', 'Slow', 'Slow',\n",
    "                  'Fast', 'Fast', 'Slow', 'Slow', 'Fast', 'Fast', 'Slow', 'Slow'],\n",
    "    'Day': ['Start', 'End', 'Start', 'End', 'Start', 'End', 'Start', 'End',\n",
    "            'Start', 'End', 'Start', 'End', 'Start', 'End', 'Start', 'End'],\n",
    "    'Accuracy (Mean)': [0.194, 0.453, 0.109, 0.484, 0.313, 0.469, 0.354, 0.406,\n",
    "                       0.521, 0.375, 0.563, 0.375, 0.547, 0.62, 0.46, 0.78],\n",
    "    'Response Time (Mean)': [2.57, 1.83, 3.48, 3.06, 2.74, 2.86, 4.67, 3.28,\n",
    "                           2.34, 1.46, 3.6, 1.93, 2.23, 1.69, 3.26, 2.2],\n",
    "    'N Trials': [160, 128, 128, 128, 48, 32, 48, 32,\n",
    "                 144, 48, 144, 48, 48, 50, 50, 50]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot Fast speeds\n",
    "fast_data = df[df['Quiz Speed'] == 'Fast']\n",
    "sns.barplot(data=fast_data, x='Group', y='Response Time (Mean)', \n",
    "            hue='Day', ax=ax1, palette='Set2')\n",
    "ax1.set_title('Fast Quiz Speed')\n",
    "ax1.set_ylabel('Response Time (seconds)')\n",
    "\n",
    "# Plot Slow speeds\n",
    "slow_data = df[df['Quiz Speed'] == 'Slow']\n",
    "sns.barplot(data=slow_data, x='Group', y='Response Time (Mean)', \n",
    "            hue='Day', ax=ax2, palette='Set2')\n",
    "ax2.set_title('Slow Quiz Speed')\n",
    "ax2.set_ylabel('Response Time (seconds)')\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.suptitle('Response Times by Group, Speed, and Day', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
